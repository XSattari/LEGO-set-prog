             \input{localstuff}

\fancyhead[LO]{Waiss Sattari}
\fancyhead[RE]{Lego Set Sort}
\fancyhead[RO, LE]{\thepage}

\hyphenation{
    hy-phe-na-tion
    num-bered
}
\usepackage{graphicx}
\graphicspath{ {./Images/} }
\usepackage{listings}

\raggedbottom
\begin{document}

\thispagestyle{empty}

\begin{center}
    \LARGE\headingfont{\textbf{Lego Set Sort \linebreak The project for my A-level NEA}}
\end{center}

\begin{center}
\vspace{4pt}
\large
    Waiss Sattari  
    
\small
   Woodhouse College 
\end{center}

\tableofcontents

\section{Analysis}
\subsection{Problem background} % talk about lego sets missing pieces etc [1]

LEGOs, according to the Encyclopedia Britannica, are \textit{"plastic building-block toys that rose to massive popularity in the mid-20th century"} \footnote[1]{https://www.britannica.com/topic/LEGO}. These tiny plastic pieces come in a range of shapes and colours, which allow them to be combined to create whatever one can imagine. The company \emph{LEGO} sells these bricks generally as parts of a set, where all the Lego pieces required to create a certain build are boxed together to be purchased and assembled by a consumer; not unlike a jigsaw puzzle.\bigskip

However, also similar to a jigsaw puzzle, pieces from a Lego set can go missing, rendering the final build incomplete. Furthermore, pieces from different sets could become jumbled up, which would require a tedious process of sorting through every single Lego piece, having to remember which pieces your set requires and how many, until you find all the pieces of a particular set. The 
more of these pieces you own, the harder this set-sorting process is.\bigskip

This is the problem I aim to solve. My project intends to aid with sorting LEGO sets, to keep a stored inventory of sets, to recognise and identify a piece for you while you sort (what I will refer to as 'scanning' a LEGO piece), and update the set accordingly. This would provide an efficient system of keeping inventory as well as aiding in sorting, which would allow the user to know what items are missing and how many so that they know what pieces to purchase to complete their set. The task of recognising LEGO pieces to aid with sorting can only be performed with the use of a machine learning model, to be able to differentiate and identify different LEGO pieces. Thus my project will revolve around creating a program that utilises AI to perform the desired task.\bigskip

The end user would of course be LEGO enthusiasts, people who own multiple LEGO sets and face the aforementioned issues of jumbled up sets and missing pieces. One such LEGO enthusiast is a teenager named Jonah. Jonah owns his fair share of LEGO sets, and has agreed to answer some questions for my research into the requirements of my "Lego Set Sort" program.

\subsection{Research}
\paragraph*{End-user aided research\\\\}


Thanks to Jonah's experience and LEGO knowledge, he has been able to provide information which I may find useful for improving my problem solution, and also present some small requirements my solution must have for it to be of any use to someone like him. Following a conversation with Jonah, I have been able to identify some key points for consideration:\bigskip 
\begin{itemize}
    \item Every LEGO piece has an element number, which identifies the shape of the piece, and a colour. LEGO pieces of a specific element and colour have a unique LEGO number which identifies the specific piece. This information on element and colour would be useful in implementation if the solution requires identifying LEGO shape and colour separately. \bigskip
    \item The LEGO number is an identification number and is unique to every LEGO piece, so this number would be great to use within the program to differentiate between every piece. Utilising this information would also be useful as the user may use this number to easily search for and purchase any missing pieces online, so as to complete their set (e.g. through a website like www.toypro.com, where you can search for a piece by LEGO number to purchase.)\bigskip
    \item Since it is usually the case that the multiple sets that are jumbled up together may contain similar pieces, the user should be able to add the same piece to multiple different sets after it has been 'scanned' by the program. \bigskip
    \item There are hundreds of different LEGO colours and tens of thousands of elements. That said, only a select few colours and elements make up the majority of pieces that exist. Using this information and focusing only on these common pieces will simplify implementation immensely. \bigskip
\end{itemize}
This provided information from Jonah does not only make my solution more efficient, but would also make it of actual use to the targeted audience, so taking these points into consideration when making my requirements are paramount.

\paragraph*{Convolutional Neural network research\\\\}% MLM research

As previously mentioned, being able to differentiate between different LEGO pieces in the process of sorting is only possible through use of a machine learning model, which will be the focus of my project. For this, I will need to implement a specific type of neural network, a convolutional neural network (CNN for short), and my neural network will use supervised learning. The following paragraphs encompass some of the research I have done on what these are for the purpose of creating my own CNN. The research I have done spanned over many hours, so I will not go into too much detail and will only provide some key points.\bigskip

Firstly, what is a machine learning? Machine learning works to uncover the underlying relationship within given data. In the case of the project it would be to find the patterns of lines/edges of images of LEGO pieces, to know which pieces have what features so as to differentiate between them. A machine learning model can be considered as a function: It takes in inputs and returns an output, and has multiple parameters (weights and biases) which it may change to alter the outputs it produces. It is not a fixed function but rather one which is 'trained' on historical data so as to best perform the task it was created for. The training can be 'supervised' or unsupervised', but the only one I am concerned with is supervised learning, as it is how I will train my model for my project.\bigskip

In supervised learning, data is fed into our model with a 'label' of the desired output so that the model can learn and tweak its parameters to improve . If we call our machine learning model \(f(x)\), and the desired outputs as \(y\), then the goal is to have our model's output as close to the desired output such that \(f(x) \approx y\) (no models can claim 100 \% accuracy so it is always an approximation). The model learns against the data and it's labels which we feed in, which is why it is called 'supervised' learning. In my case that would require feeding in images of LEGO pieces along with the LEGO number as a label. However, there are many different types of LEGO pieces, and this training process requires thousands of images to train on to be remotely accurate so it would be difficult to take and label all of these images, both expensive and tedious. Luckily, this problem can be overcome through training on virtual data, using images generated from 3D renders of pieces. It can produce more images with less effort than if I were taking images myself and as long as the 3D models are similar enough to physical LEGO pieces, the neural network won't know the difference, meaning it can train on them.\bigskip

A neural network is a subset of machine learning and it's structure is inspired by the human brain, with nodes as neurons connected in layers together to form outputs from inputs. There can be as many layers and nodes in these layers as needed, with an input layer, an output layer, and 'hidden' or 'dense' layers between them which is where the function occurs. When you input data into the network, you 'propagate' forward through the network layer by layer until the end, where an output is produced. Every node between two layers are fully connected, and these connections have a weight assigned to them. To find the value at a particular neuron, you sum the product of all neurons in the previous layer multiplied by the weight, and add the sum to a bias. You then pass this value through an activation function like sigmoid, tanh or ReLU which introduces non-linearity to the network, allowing for a more complex function. There are many neurons and connections in a neural network, so one would imagine all of these computations to be long and strenuous, however the process is simplified as the neurons and the weights / biases can be represented as matrices, thus the relevant computations may be tackled with vector calculations. If we call the matrix of our neurons of the first layer \(X\) of dimensions \(i \cdot 1\), the matrix of neurons of the second layer \(Y\) with dimensions \(j \cdot 1\), the matrix containing all weights between these layers as \(W\) with dimensions \(j \cdot i\), the matrix of biases as \(B\) with dimensions \(j \cdot 1\) and the activation function as \(\sigma\), we can write the equation for forward propagation as \[Y =\sigma(WX + B)\] The weights and biases are the parameters of the function, they dictate the output and thus may be tweaked to improve the output of the neural network.

\begin{center}
\includegraphics[width=16cm]{Images/nodes.png}
\bigskip
\includegraphics[width=16cm]{Images/equation.png}
\end{center}
These images, taken from The Independent Code on YouTube\footnote{\url{https://youtu.be/pauPCy_s0Ok}} show this. From the first image, we can see how the neurons from the first layer are multiplied to their weights, summed, and added to a bias to find the value of a neuron in the second layer. The second image shows how these may be written in vector form. The images do not display an activation function; The Independent Code, who created the diagrams, believes that the activation function could be treated as its own layer, an activation layer, which exists between two dense layers. It essentially works the same, the output of propagating forwards in the first layer undergoes the activation function in the activation layer, and then this result is fed into the second layer as input. The Independent Code chooses to do it this way as he argues that it makes the relevant code for forward and backward propagation a lot easier.\bigskip

Tweaking the weights and biases is done while testing through a process called back-propagation. It is called this because the process starts from the end of the network, and works its way to the start layer by layer while making the changes to the weights and biases. When our neural network takes input and runs it's course, it compares the output with the desired output on the label of the test data. It finds a cost function by finding the squares of the differences of the outputs with the desired output, and the goal is to minimise this cost by changing the weights and biases. This is gradient descent, and involves finding the derivative of the cost function and using this to find other derivatives via chain rule to find equations showing how much the weights and biases of a layer must change by in order to decrease the cost function. I will not go into detail about it, nor the derivation of relevant equations, but the equations are used to tweak the parameters so as to minimise the cost function. When making the changes, we use a variable called the learning rate to determine how drastically we make our changes, which has a value that we decide on. How drastically we change the values may lead to overshooting or undershooting the perfect, desired values of our parameters, and so affects the rate at which our network learns. Thus, picking the right value for the learning rate is key to minimise the time of learning of the neural network.\bigskip

A convolutional neural network is a type of neural network specialised for dealing with images. It is a neural network with an added convolutional layer, and the network may use multiple of these layers. A convolutional layer involves taking the image and running a convolution on it using a 'filter' otherwise called a 'kernel'. The kernel is slid along the pixels of the image, with the values of the pixels in the kernel and the image it overlaps multiplied, summed, added to a bias, and passed through an activation to find the value of the pixel of a new image. Once the kernel has fully slid along the whole surface of the image, a new image is generated. Multiple kernels may be used since different kernels can extract different patterns from the image, and these generated new images may then be pooled (essentially made smaller) e.g. through max pooling, which splits the image into equally sized boxes, and takes the largest value pixel from each of these to construct a smaller image. This process extracts dominant features and reduces dimensionality of the image to make it easier to compute. The smaller images are then flattened into a vector so that they be passed into a normal neural network, and an output is produced in the end using the softmax classification technique (a technique which simply scales outputs into probabilities). The pixel values of the kernels introduce yet another set of parameters which can be tweaked during back-propagation, along with their biases of course.\bigskip

\begin{center}
\includegraphics[width=16cm]{Images/CNNexample.png}
\end{center}
The image features a visual representation of the constituent layers which may make up a CNN, showing how the image size is made smaller going through layer by layer. It also decomposes the process into two main tasks, feature learning where we are extracting relevant patterns and features from the image, and classification where we run these into dense layers to identify what the image is representing.\bigskip

Sources I have used for my full research include:
\begin{itemize}
\item LeetCode machine learning 101- \url{https://leetcode.com/explore/learn/card/machine-learning-101/287/what_is_ml/}
\item A Comprehensive Guide to Convolutional Neural Networks- \url{https://saturncloud.io/blog/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way/}
\item 3blue1brown- \url{https://youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi}
\item far1din- \url{https://youtube.com/playlist?list=PL1sQgSTcAaT7MbcLWacjsqoOQvqzMdUWg}
\item The Independent Code- \url{https://youtu.be/pauPCy_s0Ok}
\end{itemize} 

\paragraph*{Existing solutions\\\\}

There are no current solutions to my exact problem of sorting LEGO pieces by set as far as I can find searching online, though there does exist LEGO sorting machines which sort Lego pieces by colour or piece type. They do not feature the functionality of storing and manipulating sets as mine does, but the AI they use in identifying the LEGO piece to sort is the same as what I aim to create for my project, so in that regard it is similar.\bigskip


One of the most popular of these is the "Universal LEGO Sorting Machine" created by a man named Daniel West, which he features in a semi-viral video on YouTube\footnote{"The WORLD'S FIRST Universal LEGO Sorting Machine": \url{https://youtu.be/04JkdHEX3Yk}}. In the video we see the impressive hardware dedicated to the task of moving and physically sorting the bricks, but this is not a focus of my own project. He does not go into detail about the software aspect of his build in this video. However, on his YouTube channel, West has another video uploaded which does, a video dedicated to the AI of his machine\footnote{"LEGO Sorter AI: How Does It Work?": \url{https://youtu.be/-UGl0ZOCgwQ}}. \bigskip 


In this video, we see that Daniel West also utilises a convolutional neural network, and see he also tackles the problem of getting thousands of labeled training data by using 'synthetic data', computer generated images with labels attached. Unfortunately however, West explains that using this synthetic data does not work due to a problem he calls the "Sim-to-Real problem", where the subtle differences in things like lighting, shadow and texture in the generated images- things we may not pick up on ourselves- throws the neural network off completely. He claims that the problem remains unsolved, but that he was able to use a technique published from a paper in 2017 to get around the problem, called Domain Randomisation. The gist of it is that instead of trying to create generated images which match the physical LEGO pieces perfectly, we generate images with a large range of randomised colour, lighting, background and material, and use these images instead to train the neural network. Because of the large variation, the CNN is able to pick up on the underlying relationships of the data better, so as to not be thrown off by subtle differences in texture and lighting anymore- building what West calls "much better quality connections in the brain", so performing better in recognising physical Lego pieces.\bigskip


Daniel West then goes on to explain how he further improves his results by "Fine Tuning", where he takes a small number of real life LEGO images and does a bit more learning with these to essentially fine tune the neural network. He claims that it results in much more accurate predictions even if only a small number of images are used in this step. Learning from Daniel West's solution will greatly improve my own. Utilising domain randomisation in my own machine learning model will be integral in getting it to actually function, as I now know that generated images by themselves do not work. The fine tuning step will also significantly enhance my own results, and overall will lead to a more accurate convolutional neural network.

\subsection{Proposed solution} % my project

My solution features two key aspects. The first is the scanning of LEGO items by image to identify them with use of a CNN, and the second is to allow the user to keep an inventory of their sets within the program. The first aspect may be used as a standalone feature by the user, who might not want to concern themselves with creating an inventory of their sets and only with to use the LEGO identifying capabilities of the neural network. However, the first aspect also stands to act as an extended functionality of the second: that is, to be used for the purpose of adding LEGO pieces which are scanned to a stored set, which may be used for example when a user is physically sorting through sets. Thus, these two aspects are not completely intertwined nor completely independent. \bigskip


 For the AI to interact with the physical world and "see" the piece it is working with, there is need of a camera. It would therefore be effective if the program could make use of a mobile device, as these are widely available (nearly everyone owns a mobile phone) and so would be convenient for the target audience. It also eliminates the need to purchase extra hardware like a webcam/document camera, which makes it inexpensive both for the user and for myself in the development of this project. \bigskip
 
 However, I do not aim to create a mobile application as I have no experience doing so, and the neural network I create may prove too computationally demanding, especially a problem for those with older/cheaper phones. My solution to this is for the phone to only be used for its camera- that is, to have the program run from a PC with the phone connected to it if and when the user wants to use their phone to "scan" a piece. Doing so can be achieved through an IP webcam application downloaded on the phone, and use of the "OpenCV" library in my code to connect to the phone's camera. Alternatively, there can be the option on the program to upload a file of an image of the LEGO, so the user may choose to take photos using any device of their choice before transferring the files to their PC by whatever means, so that they may upload these files in the program to be used to "scan". This added functionality would also allow the user to scan images of LEGO they find online, or images they are sent by friends, without the need to physically own the LEGO themselves.\bigskip

Regarding the second key aspect, my solution will provide the functionality for the end user to input the information of the set(s) they possess including LEGO number of the item, the amount required of the item and the amount that is currently owned. Storing this data will be done using text files. Upon starting the program, all files are read from to initialise the sets in the program, and the text files are updated after any changes are made by the user to a set. For added practicality, I would like my solution to also provide the user with information on things like element number and colour of an item in a set, and for the items within a set to be sorted by its attributes ascending or descending, such as by LEGO number, element number, colour, amount owned, amount required, or amount needed to complete a set. \bigskip

As for the first key aspect, my solution will feature a method to identify LEGO pieces by an image, received by phone or by uploaded file as previously mentioned, and this is where the 'AI' of the solution is utilised. However, there is a glaring issue with this aspect- there are many different LEGO pieces which would appear similar to the neural network, since different LEGOs share the same shape and colour. The neural network would have to be very large and complex to differentiate between both shape and colour, which would greatly increase time training, computational demand of training, and would require a very large labelled dataset- something that would be very difficult to obtain. \bigskip

To combat this issue, I have decided to instead identify a LEGO item's element and colour separately. Every LEGO piece has a unique element and colour combination, therefore a LEGO item and its identifying number can be deduced from knowing the element number of the piece and its colour. Therefore, the element and colour of the piece will be determined with separate neural networks, and these will be used to determine the LEGO number of the item from a hashtable. After identifying the item, the user is then presented with the information- which includes the LEGO number, element number and colour- after which they may choose to add this item to a set(s) at a specified amount. \bigskip

There are a few online datasets for LEGO pieces. For my solution I will use a dataset from Kaggle by Joost Hazelet.\footnote{https://www.kaggle.com/datasets/joosthazelzet/lego-brick-images} I will not be using the entire dataset, rather I will be hand picking certain LEGO elements. As mentioned by Jonah the LEGO enthusiast, the most common elements make up a large proportion of existing pieces, so it is imperative I focus on these. I will determine what elements by finding the overlap of elements in the dataset and the elements that exist in the top 30 most common elements using a website 'Brick Architect'.\footnote{https://brickarchitect.com/most-common-lego-parts/} From these elements I will select 'nice' images, where the angle of the piece is adequate enough to determine the element easily. This is all for the purpose of making differentiation as easy as possible for my neural network, given that the task is complicated and I do not have access to great resources or time.\bigskip

As for the image classification, I will create an algorithm to deduce an RGB value representing the RGB colour of the LEGO piece from an image. The issue is that although LEGO items have discrete colours, images of items are affected by things like glare, shadows, etc. Thus, the RGB values of two LEGOs of the same colour from separate images will differ from each other. To combat this, I will use another neural network dedicated to identifying a LEGO colour by the RGB value, using a dataset created by the 'ICT Institute'.\footnote{https://ictinstitute.nl/legocolor-computer-vision-dataset/}\bigskip

I have decided to create my solution using python. I picked Python as many websites rank it first place for "Best language for Machine Learning"\footnote{One such of these websites is https://www.springboard.com/blog/data-science/best-language-for-machine-learning/}, but also as it is a language I am proficient in. Furthermore, it is an object oriented programming language, which is a great paradigm to use for a CNN as it features many loosely related types of layers, and also good since my solution will utilise a lot of classes, for things such as sets and LEGO but also for data structures like stacks or the hashtable. \bigskip

My project does come with many limitations. Of course, there exists the time constraint- creating an AI and testing it on data to a satisfactory level of efficiency is a lengthy process, so given the time constraint my machine learning model may not be as accurate as I could make it. Training my CNN to recognise even a single Lego element would require a great load of images of that one piece, so time will also affect the number of different Lego elements my CNN may learn to recognise. Thus, my machine learning model will be limited in the number of Lego pieces it may recognise.Furthermore, testing a neural network is usually done on expensive equipment over the course of days or even weeks. This represents a monetary limitation as I do not have such resources on my PC, and do not wish to waste too much electricity training. This would affect training time and thus accuracy, and again I would have to make compromises with the amount of elements my neural network can recognise. A limitation of the inventory aspect is the efficiency in which the Lego set information is input into the system by the user. It may prove tedious to have to manually input all the information, especially for large Lego sets. I do not wish to bite more than I can chew, so I will have to make do with a simple implementation of the inventory aspect, which would allow me to focus on the neural network aspect.\bigskip

\subsection{Project objectives} % High+Low level requirements: machine learning models, ui, etc
My objectives are split into two categories, the Neural Network aspect and all it encompasses, and the main program aspect- which would include the stored inventory aspect and all other functionalities of the program. These categories are split into their key objectives, which are broken further into smaller sub objectives. All objectives are ranked by their importance. High-level objectives are denoted with 'H', while low-level objectives are denoted with an 'L'. High level objectives take high priority in being implemented and are what I deem integral to the solution, while low level objectives represent added features and functionality which would be nice to include in the program, or features which would only prove to improve the final solution but are not necessary.\bigskip

Neural network aspect:
\begin{enumerate}
    \item H- There exist the Layer classes, a Neural Network class and a class for all the functions used by these two classes.
    \begin{enumerate}
        \item H- The class of functions will comprise of all the functions related to manipulating matrices. This will include creating a matrix of a given size, creating an identity matrix of a given size, matrix addition, subtraction, transposing a matrix, dot product of matrices, hadamard product of matrices, scaling a matrix, raising the matrix to a power, finding the dimensions of a matrix, changing the dimensions, rotating a matrix, and copying a matrix. It will also include the special matrix operations used by the convolutional layer and max-pooling layer, being to perform a convolution of a matrix with another, and to pool a matrix. Other functions in this class includes calculating the mean-squared error and finding the rate of change of the error, both used for back-propagation, and finally a function to shuffle a list of data, which will be used in shuffling training data when training a neural network.
        \item H- The layer classes will all inherit from a base template layer class, with attributes of input, output, rate of change of these, and base methods of forward propagation, backward propagation, and a method to get the type of layer. These methods will all be overridden and implemented differently by the specialised children classes, and these children classes will have their own attributes as well as getters and setters for these. The layers to implement include:
        \begin{enumerate}
            \item H- Hidden layer, aka fully connected layer
            \item H- ReLU activation layer, introduce non-linearity
            \item H- Softmax activation layer, assigning probabilities to output
            \item H- Convolutional layer, for the CNN
            \item H- Max-pooling layer, for the CNN
            \item L- Dropout layer, for reducing over-fitting of data in training
        \end{enumerate}
        \item H- The neural network class will create an object that holds layer objects, and is essentially the neural network being used. The object will be given a name upon initialisation, which could be used to reference the purpose of it, and it will have the methods to add layers to the neural network object. Other functionalities of the class includes:
        \begin{enumerate}
            \item H- The ability to propagate forwards and backwards through all layers.
            \item H- The functionality to train the neural network on given data using the features listed directly above. Trains on every piece of data for a fixed amount of times specified by the epochs.
            \item L- Training is done based on batch size. A forward propagation is run with data for the amount specified by the batch size, the mean of the rate of change of errors is found, and then this is what gets used to perform backwards propagation.
            \item H- The ability to save a neural network object to a file, and to upload a saved neural network from this file. This feature is imperative.
            \item L- Display the layers held in the neural network object.
        \end{enumerate}
    \end{enumerate}
    \bigskip
    
    \item H- Image data is augmented when used to train (domain randomisation)
    \begin{enumerate}
        \item H- Image undergoes geometric augmentations. The augmentation is decided randomly from multiple options, or multiple augmentations may be applied at once. These would include:
        \begin{enumerate}
            \item H- Crop. This crops the image in such a way that the object remains in the image but is off-centred randomly
            \item L- Rotation. This rotates the image by a random angle.
            \item L- Zoom. This zooms into the image to make the object take up more space in it, while still being fully visible in the image.
        \item H- Image undergoes non-geometric augmentations. These include:
        \begin{enumerate}
            \item H- Brightness. How much image is dimmed decided randomly.
            \item L- Contrast. Again, decided randomly.
            \item H- Sharpness. How blurry image is decided randomly.
        \end{enumerate}
        \end{enumerate}
    \end{enumerate}
    \bigskip
    
    \item H- The image and element of a LEGO item can be deduced from an image
    \begin{enumerate}
        \item H- The element is deduced by having the image passed scaled to an appropriate size before being passed into the element CNN.
        \item H- An algorithm finds the RGB value of the LEGO item from an image
        \item H- The RGB value deduced from an image is passed into a NN for determining the colour of the LEGO item.
        \item H- A hashtable data structure exists which takes element and colour as a key, and has the LEGO number as the value. Upon initialisation of the program, a file containing information on all elements, colours, and LEGO numbers is read, which is used to initialise the hashtable.
        \item H- The element and colour are used to find the LEGO number from the hashtable, and all this information is relayed to the user.
    \end{enumerate}
    \bigskip

Main program aspect:
    \item H- There exists classes for Sets, LEGO pieces, and a class 'AllSets' that contains all the sets in the program.
    \begin{enumerate}
        \item H- The 'AllSets' class contains a list set objects, with options to add and remove sets, as well as getters and setters.
        \item H- The Set class contains a list of LEGO objects. The class contains information on the set such as its name, whether the LEGOs in it have a required amount or not, and how they are sorted and displayed in the set. It also contains methods to manipulate these attributes.
        \item H- The LEGO class contains information on the item's LEGO number, which it uses to deduce its attributes for element and colour, done so using another hashtable that instead uses the LEGO number as a key and the element and colour as values. It also has attributes of amount and required amount, and has methods to manipulate these.
        \item H- A folder contains files with information on all sets. In this file is stored the names of all sets in the program, and initialised into an all sets object when the program is run.
        \item H- There also exists files in the folder for every set, with the exact name of the set. These contain information on the sets attributes, and for the LEGO pieces in the set including their amounts. This is also all initialised into objects at the start of the program.
        \item H- Making any changes to sets or items or amounts leads to changing the objects that represent them, which are then used to update the files stored such that changes made are saved.
    \end{enumerate}

    \item H- Sets and the items they contain can be manipulated by the user.
    \begin{enumerate}
        \item H- Sets can be added or deleted, and must have a unique name.
        \item L- Sets can be uploaded from a stored database of existing official LEGO sets.
        \item L- Sets can be duplicated under a different name or backed up to be restored.
        \item H- Within a set, set information and the LEGO items of the set are displayed, including the items LEGO number, element, colour, amount, required amount and a small image of the LEGO item.
        \item H- The set also displays statistics of the set, such as the number of different LEGO items, and the total number of pieces. If the set has a required amount for pieces, then it also displays the total number required and a percentage of how complete the LEGO set is. \item L- Sets can be filtered by element or by colour.
        \item H- Set information can be changed. This includes:
        \begin{enumerate}
            \item L- Changing whether or not the set's pieces have a required amount
            \item L- Changing the set's name
            \item H- Changing how the set sorts its LEGO items. Sorts can happen by LEGO number, by element, by colour, by date added, by amount inset, by amount required, by amount needed to fulfill required and by percentage of required currently owned. This can all be done ascending or descending.
        \end{enumerate}
        \item H- LEGO items within the set can be changed. This includes:
        \begin{enumerate}
            \item H- Changing the amount of the item in the set.
            \item H- Changing the amount required in the set, if it has amount required.
            \item H- Removing an item from the set.
            \item H- Adding an item to the set. This can be done by LEGO number, or directs user to 'scan' a LEGO image.
            \item L- Min/max the amount of all items in the set. Min sets to 0, which is useful if user wishes to begin sorting set again from jumbled up LEGO and store the new amounts in the program's set. Max sets amount to amount required, if there is an amount required.
        \end{enumerate}
        \item H- When making changes to set, user is taken to separate screen. After making their changes, they may save changes or exit, which cancels all changes made.
    \end{enumerate}
    \bigskip

    \item H- Main program uses a stack to store 'states' of the program that the user interacts with. As the program runs, the top "state" is constantly in effect.
    \begin{enumerate}
        \item H- States are represented by functions, and are essentially the screens that the user sees.
        \item H- Upon entering a new state, the function of the state is pushed onto the main program stack.
        \item H- If the user wishes to return to the previous screen, then the current state is pushed off of the stack.
        \item H- Every function takes the main program stack as an argument. The main program stack object is also used to carry around data between the stacks, such as hashtables and the AllSets object.
    \end{enumerate}
\end{enumerate}

\section{Design}
\subsection{Overall system design}

My solution will have the functionality to identify a LEGO item from an image, and to hold a stored inventory of LEGO sets for the user. 


\begin{center}
\includegraphics[width=10cm]{Images/hierarchy-Page-1.drawio2.png}
\end{center}

At the highest level of abstraction, this hierarchy chart demonstrates the subroutines of the main program. It displays the core functionalities my solution requires, decomposed into the two distinct sections of LEGO identification and LEGO storage. \bigskip

Identifying the LEGO requires the image being uploaded, and finds the RGB value of the LEGO deduce the LEGO colour. It then finds the LEGO element, and uses colour and element to get the LEGO number. Finding element and colour makes use of machine learning models. Creating these involved implementation, training, and tweaking of parameters, which took a great deal of time and effort and made up the bulk of the creation of the solution. Thus, the hierarchy chart of the main program represented above is merely the tip of the iceberg of the solution. \bigskip

The LEGO storage aspect performs the task of retrieving stored LEGO data and set data. It deals with the altering of set information, and updating the stored set data to the new altered data. \bigskip

\subsection{Main program flowchart}

The flowchart below illustrates the processes that take place when the main program is run. The main program makes use of a 'main program stack' and 'program states' to provide the interface for the user to utilise the functionalities of the program. The program states essentially represent the different 'screens' presented to the user as the program runs, and are implemented as subroutines. The functionalities of the program state includes displaying text to the user, getting input from the user, performing specific tasks, and flowing to other states, and all functionalities are implemented differently specific to the purpose of the state.

\begin{center}
\includegraphics[width=4.5cm]{Images/flowchart.drawio.png}
\end{center}

Once the program is run, it begins by retrieving stored LEGO data. This data includes a list of all the LEGO colours and LEGO elements that the program can identify, as well as the LEGO numbers of all items that have these specific elements and colours, and all of this data is stored in a file. Retrieving the data produces two arrays, one containing the colour and one the element, and two hashtables. One hashtable allows for the LEGO number of an item to be looked from its colour and element, and another does the reverse, finding the colour and element of a LEGO item from the LEGO number. \bigskip

The program then creates the main program stack, which is an object implemented as a stack data structure but with attributes and getters/setters for these attributes to allow data to be accessed by the program states as the program runs. This data includes the stored LEGO data we just retrieved, thus the object is initialised with the arrays and hashtables. \bigskip

After this, the information of the user's sets is retrieved from the files that store them, which includes a file containing the names of every set, and a separate file for each of these sets. Each set is made into a set object, containing LEGO objects of items in the set, and all sets get added to an AllSets object, which is stored in the main program stack, which gives program states access to all the sets and the items in each set during program execution. \bigskip

The 'Home screen' program state is then pushed onto the main program stack, as the starting state of the main program. Finally, the main program runs an indefinite loop of executing the state at the top of the stack. During the execution of the state, it may push another state to the top of the stack, or pop itself off, which would result in a different state being the current state. Different states and how they link are covered in more detail later. \bigskip

\subsection{Stack and hashtable data structures}

\paragraph*{Main program stack\\\\}

The main program stack is implemented as a stack data structure. This means that it can store items, in a last in first out 'LIFO' basis, and has the methods to push, peek and pop items. \bigskip

The stack contains an array which stores items, and has a top pointer initialised at index 0 of the list. When an item is being pushed onto the stack, the item is added to the array at the position of the pointer, and the pointer is incremented by one. In performing a peek, the item at the index of the pointer minus one- the item below the position of the pointer- is returned. This is only done if the value of the position is greater than zero, otherwise the stack is empty and there is nothing to return. The same is true in performing a pop. If the pointer is larger than 0 the stack is not empty, so the pointer is decremented by 1 and the item at the index of the new pointer is removed, which can be achieved simply by popping the last item from the array.

This is all represented in the diagram below. The stack at the top represents a stack object before any actions are performed on it. Below it is the same stack after performing a push, then a peek, and finally a pop, which returns it back to its original state.

\begin{center}
\includegraphics[width=15cm]{Images/stack2.drawio.png}
\end{center}

Aside from having the functions of a stack data structure, the main program stack also has attributes which allows it to hold any data required by program states during their execution. This includes data on LEGO colours/elements, hashtables, and the AllSets object which allows access to every set and their constituent items. These attributes have getters and setters to retrieve and change them. The main program stack class is summarised in the class definition below. \bigskip


\begin{table}[h!]
\begin{tabular}{|l|l|l|}
\hline
\begin{tabular}[c]{@{}l@{}}Object\\ variables\end{tabular} & Type    & Description                                                                                                                                         \\ \hline
Stack                                                      & List    & Holds the items stored in the stack                                                                                                                 \\ \hline
Pointer                                                    & Integer & \begin{tabular}[c]{@{}l@{}}Points at the location above the last item in the stack. \\ Value represents index of this location\end{tabular}         \\ \hline
CurrentImg                                                 & Object  & The image that the program is currently working with                                                                                                \\ \hline
CurrentSet                                                 & Object  & The set that the program is currently working with                                                                                                  \\ \hline
Elements                                                   & List    & Contains all LEGO elements that the program recognises                                                                                              \\ \hline
Colours                                                    & List    & Contains all LEGO colours the the program recognises                                                                                                \\ \hline
ColourElemHashtable                                        & Object  & \begin{tabular}[c]{@{}l@{}}Hashtable that takes a  colour and element, and returns the \\ LEGO number of the item with these qualities\end{tabular} \\ \hline
NumberHashtable                                            & Object  & \begin{tabular}[c]{@{}l@{}}Hashtable that take a LEGO number and returns the colour \\ and element of this item\end{tabular}                        \\ \hline
AllSets                                                    & Object  & Object which contains objects of every set in the program                                                                                           \\ \hline
\end{tabular}
\end{table}
\bigskip

The main program stack object is instantiated with Elements, Colours, ColourElemHashtable and NumberHashtable taken as arguments. The stack is initialised as an empty list, and pointer as the integer 0. CurrentImg, CurrentSet, and AllSets are initialised as None.\bigskip


\begin{table}[h!]
\begin{tabular}{|l|l|l|}
\hline
Method                                                            & Input/Output                                                           & Description                                                                                                                                                         \\ \hline
Push                                                              & Input: program state                                                   & \begin{tabular}[c]{@{}l@{}}Pushes program state onto the stack. Added to \\ stack list at index of pointer, and the pointer is \\ incremented by 1\end{tabular}     \\ \hline
Pop                                                               & None                                                                   & \begin{tabular}[c]{@{}l@{}}If pointer larger than 0, pops last item from stack \\ list. and decrements pointer by 1. Otherwise, print \\ "stack empty"\end{tabular} \\ \hline
Peek                                                              & Output: program state                                                  & \begin{tabular}[c]{@{}l@{}}If pointer larger than 0, returns the item from stack \\ list at index of pointer - 1. Otherwise, print \\ "stack empty"\end{tabular}    \\ \hline
GetElements                                                       & Output: elements list                                                  & Returns list of elements                                                                                                                                            \\ \hline
GetColours                                                        & Output: colours list                                                   & Returns list of colours                                                                                                                                             \\ \hline
\begin{tabular}[c]{@{}l@{}}GetColourElem\\ Hashtable\end{tabular} & \begin{tabular}[c]{@{}l@{}}Output: ColourElem\\ Hashtable\end{tabular} & \begin{tabular}[c]{@{}l@{}}Returns hashtable that has LEGO numbers as \\ values\end{tabular}                                                                        \\ \hline
\begin{tabular}[c]{@{}l@{}}GetNumber\\ Hashtable\end{tabular}     & \begin{tabular}[c]{@{}l@{}}Output: Number\\ Hashtable\end{tabular}     & \begin{tabular}[c]{@{}l@{}}Returns hashtable that has colours and elements \\ as its values\end{tabular}                                                            \\ \hline
GetImg                                                            & Output: image                                                          & \begin{tabular}[c]{@{}l@{}}Returns the image that the program is currently \\ working with\end{tabular}                                                             \\ \hline
SetImg                                                            & Input: image                                                           & \begin{tabular}[c]{@{}l@{}}Sets current image of program to the inputted \\ image\end{tabular}                                                                      \\ \hline
GetSet                                                            & Output: set                                                            & \begin{tabular}[c]{@{}l@{}}Returns the set that the program is currently \\ working with\end{tabular}                                                               \\ \hline
SetSet                                                            & Input: set                                                             & Sets current set of program to the inputted set                                                                                                                     \\ \hline
GetAllSets                                                        & Output: AllSets                                                        & Return AllSets object                                                                                                                                               \\ \hline
SetAllSets                                                        & Input: Allsets                                                         & \begin{tabular}[c]{@{}l@{}}Sets the AllSets attribute to the inputted \\ AllSets object\end{tabular}                                                                \\ \hline
\end{tabular}
\end{table}
\bigskip

\paragraph*{Hashtable\\\\}

A hashtable is a dictionary which takes a key, performs a hash function on the key to get an index, and checks an array at the position of the index for the value. However, it is nearly always the case that two keys produce the same index, in what is known as a collision. In the event this happens, the hashtable must handle the collision. \bigskip

Items are added to a hashtable as a list containing the key and the value. If two keys produce the same index location, then the hashtable can simply add the key-value pair to the next available location in the table. When it comes to finding an item, the hashtable goes to the index location calculated with the key and compares the key to the key at the location. If it is a match, then it can return the value. If not, then it knows to keep searching contiguous locations to eventually find what it is looking for. If it reaches an empty location, it knows the value was never added so the hashtable doesn't contain it. This is one way to handle collisions. However, this process can result in many computations to eventually find the value or to deem it not in the table. Thus, I implemented collision handling in a different way. \bigskip

My solution instead adds items to a hashtable as a list containing a key, a value, and an empty list. The empty list contains the index locations of collided items. When adding an item, if the table already contains an item at the calculated index location, it runs the same process of finding the next available location. However, this time it gets the index value of the new location and adds it to the collided items list at the original index location. Thus, when it comes to finding an item, if the key at the location does not match, then the hashtable checks the locations for each index in the collided items list at this location. It compares its key to the key at each of these locations, and if it finds a match it has found the item it is looking for. If it finds no matches from any of these locations, then it knows the item does not exist in the table. This method of a collided items list pointing to locations of collided items requires less computations than the first method, especially so the more collisions that occur. \bigskip

The hashtable has a fixed size, the value of which can affect the number of collisions that occur. Generally the less collisions the better, as it means retrieving a value requires less computations in searching for it. Another factor that affects the number of collisions is the hash function used, as different functions result in different indexes calculated and ideally the function should produce as little duplicate indexes from different keys as possible. For my hashtable I decided to use a table size of 179 and a hash function of \( (key*3)\) mod \(size\). Modding by size ensures that the calculated index is always in range of the table. I picked this size and function as they have resulted in the least amount of collisions, found through trial and error. \bigskip

The class definition below details the attributes and methods of the hashtable class.\bigskip

\begin{table}[h!]
\begin{tabular}{|l|l|l|}
\hline
\begin{tabular}[c]{@{}l@{}}Object\\ variables\end{tabular} & Type    & Description                                                            \\ \hline
Size                                                       & Integer & The size of the hashtable, max number of items it can contain          \\ \hline
Contents                                                   & List    & The table itself, a list of fixed size specified by the size attribute \\ \hline
Collisions                                                 & Integer & The number of collisions from adding items to hashtable                \\ \hline
NoOfItems                                                  & Integer & Total number of items that have been added to the hashtable            \\ \hline
\end{tabular}
\end{table}
\bigskip

A hashtable object is instantiated with Size taken as an argument. The contents is initialised as a list of None values, of size Size. Collisions and NoOfItems are both initialised as 0. \bigskip

\begin{table}[h!]
\begin{tabular}{|l|l|l|}
\hline
Method        & Input/Output                                                                         & Description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \\ \hline
GetContents   & Output: Contents                                                                     & Returns the list of contents of the hashtable                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \\ \hline
HashKey       & \begin{tabular}[c]{@{}l@{}}Input: key\\ Output: index\end{tabular}                   & \begin{tabular}[c]{@{}l@{}}Returns the index calculated from passing key through\\ a function. Index = (key*3) mod size. Mod by size\\ ensures index is in range of table.\end{tabular}                                                                                                                                                                                                                                                                                                                                                              \\ \hline
SetItem       & \begin{tabular}[c]{@{}l@{}}Input: index, key,\\ value\end{tabular}                   & \begin{tabular}[c]{@{}l@{}}If NoOfItems equal to Size, return "table full".\\ Otherwise, increment NoOfItems by 1. If location\\ at index is None,  there is no collision,  so add \\ {[}key, value, {[}{]}{]} to this location. If there is a collision, \\ then increment collisions by 1, and keep checking\\ subsequent index locations until empty location found.\\ Add {[}key, value, {[}{]}{]} here,  get the index of this location\\ and add it to the collided items list of original location.\end{tabular}                              \\ \hline
GetItem       & \begin{tabular}[c]{@{}l@{}}Input: index, key\\ Output: value or\\ False\end{tabular} & \begin{tabular}[c]{@{}l@{}}Check contents at index. If it is None, item not in table.\\ Return False. Otherwise, compare key to key at index.\\ If match, return value from this index. Otherwise, there\\ could have been a collision. Check collided items list at\\ this location. For every index in the list, compare key to\\ the key at this index location. If there is a match, return\\ the value from the location of the matched key. If there\\ are no matches for all index locations, item not in table.\\ Return False.\end{tabular} \\ \hline
GetCollisions & Output: collisions                                                                   & Returns the number of collisions                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \\ \hline
GetNoOfItems  & Output: NoOfItems                                                                    & Returns the total number of items in the hashtable                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \\ \hline
\end{tabular}
\end{table}

\subsection{The Convolutional Neural Network}

\paragraph*{The Layer class\\\\}


Neural networks are constructed from multiple layers, where data flows through each layer in forward or backward propagation. Implementing the AI for the program will involve creating these constituent layers, putting them together in a specific order to form a neural network, and finally training the neural network on data.\bigskip

As mentioned in the \textit{Proposed Solution} section, the fact that the CNN is formed of different layers- some loosely related- makes OOP a great programming paradigm to use in creating the neural network. The different layers may be implemented as different classes, all of which inherit from an abstract class \textit{Layer} which has virtual methods for propagating forwards and backwards. The different children classes can override these methods with their different implementations of propagating, so as to be specialised for their purpose within the neural network. The different types of layers to be implemented are displayed below. \bigskip

\begin{table}[h!]
\centering
\begin{tabular}{|l|l|}
\hline
\multicolumn{1}{|c|}{Layer}   & \multicolumn{1}{c|}{Function}                                                                                                                       \\ [0.5ex] \hline \hline
Hidden &
  \begin{tabular}[c]{@{}l@{}}A layer of neurons. Contains the parameters which we tweak in training that\\  allows the neural network to make classifications.\end{tabular} \\ \hline
ReLU &
  \begin{tabular}[c]{@{}l@{}}Rectified Linear Activation, the activation function. Introduces non-linearity,\\  aids in complex pattern recognition.\end{tabular} \\ \hline
Softmax &
  \begin{tabular}[c]{@{}l@{}}Transforms the raw output of neural network into a probability distribution,\\  essentially gives the probability of all outputs. \end{tabular} \\ \hline
Convolutional &
  \begin{tabular}[c]{@{}l@{}}Extracts different patterns/features from an image, creates "feature maps".\\  These allow for better classification of original image.\end{tabular} \\ \hline
Pooling &
  \begin{tabular}[c]{@{}l@{}}Takes feature map from convolutional layer, reduces dimensionality\\  (makes image smaller) to decrease amount of computations required\end{tabular} \\ \hline
\end{tabular}
\end{table}

\bigskip
Each layer takes in an input and produces an output, which becomes the input for the layer after it. This can happen in forward propagation where the CNN tries to classify an image, or in backwards propagation where the layer calculates rates of change to use in updating parameters. Since all the layers share these attributes and methods, they may be implemented in the \textit{Layer} class, the  abstract class which all the layers in the CNN inherit from, as shown in the following inheritance diagram. \bigskip

\begin{center}
\includegraphics[width=14cm]{Images/Inheritance.png}
\end{center}

The layer class represented in class diagram form:\bigskip

\begin{table}[h!]
\centering
\begin{tabular}{|l|}
\hline
\multicolumn{1}{|c|}{Layer}                                    \\ \hline
\begin{tabular}[c]{@{}l@{}}input\\ output\\ dE\textunderscore dI\\ dE\textunderscore dO \end{tabular}         \\ \hline
\begin{tabular}[c]{@{}l@{}}forward()\\ backward()\end{tabular} \\ \hline
\end{tabular}
\end{table}
\bigskip
The forward method takes in the input for the layer as a parameter- which is the output of the previous layer or the input image itself- and does stuff to it to create an output which is passed along.\bigskip


In backwards propagation, the final layer calculates the rate of change of the error with respect to its output. Using this, the layer can find the rate of change of its parameters (e.g weights/biases) with respect to the error via chain rule, and so can change the parameters to decrease the error, which is the goal of training. The rate of change of the error with respect to output may also be used to calculate the rate of change of error with respect to its input, which is essentially the rate of change of error with respect to the output of the \textit{previous} layer, since the input of a layer is the output of a preceding layer. The preceding layer can then use this to change its own parameters and find the rate of change of error with respect to its own inputs, and this process carries on until every layer has updated its weights.\bigskip


With this, we know that the backward method needs to take in the rate of change of error with respect to its output as a parameter, and uses it to update itself and calculate rate of change of error with respect to its input.\bigskip

Overall, the attributes of a layer are its input, output, rate of change of error with respect to its input, and the rate of change of error with respect to its output (represented as \textit{dE\textunderscore dI} and \textit{dE\textunderscore dO} respectively). These values are not initialised with the layer, but are calculated as the neural network runs its course. Thus, the code to create our Layer abstract class ends up looking like this.\bigskip


\begin{lstlisting}[language=Python]
class Layer:
    def __init__(self):
       self._input = None
       self._output = None
       self.dE_dO = None
       self.dE_dI = None
       
    def forward(self, _input):
        pass
    
    def backward(self, dE_dO):
        pass
\end{lstlisting}
\bigskip

\paragraph*{Neural Network Class\\\\}

The basic building blocks of the neural network, the different layers specified previously, must have a way of being connected to each other so as to perform their functions of forwards and backwards propagation. To achieve this, I will create a \textit{Neural Network class}. This will allow for the instantiation of a \textit{Neural Network object}, which will house the Layer objects in their specified order, and allow for the implementation of different neural network methods such as running, training, and saving state. \bigskip 


There exists a \textit{has a} relationship, with a Neural Network object having many Layer objects related to it. There is no need for a layer to exist independently of a Neural Network; The layer only has a function when it is part of a neural network, and multiple neural networks cannot share the same layer as the parameter values of the layer will be unique and specialised for the neural network it exists in. Considering this, it would make more sense that the association between the objects is \textit{composition} and not \textit{aggregation}. This means that there is a strong relationship between a neural network object and a layer object that exists in it: The layer is only created to exist in the neural network that it is instantiated in, and serves no value if the neural network object that contains it ceases to exist. \bigskip 

INSERT ASSOCIATION DIAGRAM, then deleted paragraph\bigskip 

\paragraph*{Dense Layer\\\\}

Propagating forwards in a dense layer is explained in the research section of the analysis, and as was mentioned can be simplified by with vector calculations as the neurons, weights and biases can be represented as matrices. The equation for this is Y = W X + B where Y is the matrix of neurons of the first layer, X is the matrix of neurons of the second layer, W is the matrix of all weights between neurons of each dense layer and B is the matrix of biases of the second layer.\bigskip



\end{document} 

 NOTES:
FIX FUNCITONALITY OF ADDING LAYERS V LOADING UP THEM. CHECK FOR PERIM VALS BEFORE INITIALISING A LAYER W THEM.

Class method. Displays the names of all saved neural networks.


Static method. Takes name of neural network as parameter. If a saved neural network exists
with this name, then it loads the NN- initialises an object of this saved NN using the stored
information of its layers and parameter values, creating an exact replica.


Adds a layer to the neural network. Network-Layers list updated. 

deleted paragraph:
Initialising a neural network object will require a name, to identify the NN. Upon initialisation, a \textit{Network_Layers} list will be created, that stores all the layers in the neural network.
As for the methods of the Neural Network Class, it will of course need the ability to initialise and add the different types of layers into the neural network object. With the layers, the NN class will need the fundamental operations of forward propagation and backwards propagation, where it propagates through every single layer one after the other and returns an output. Building on these two methods, the class will have a \textit{learn} method where it runs a single training cycle, and then from this a \textit{training} method where training data is used to run multiple training cycles. Once the neural network has completed training and is able to perform its task, it will need a way to be saved so that it can be used later without having to re-train it. Thus, a \textit{save_NN} and \textit{load_NN} method will be needed. For added functionality, the NN class will have a \textit{view_saved} method to view all saved neural networks so the user can know what NNs can be loaded, and this method will use a class variable list that exists to store all saved neural networks. \bigskip 
