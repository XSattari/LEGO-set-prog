from matrices import mm
from layers import *

class NN:
    def __init__(self):
        self.layers = []
        
    def addLayer(self, layerObject):
        layerObject.setIndex(len(self.layers))
        self.layers.append(layerObject)
        if len(self.layers) > 2:
            if layerObject.getType() == "Hidden" and self.layers[-3].getType() == "Hidden":
                xavier = 1/(self.layers[-3].getNeurons())
                self.layers[-3].setWeights(mm.makematrix(layerObject.getNeurons(), self.layers[-3].getNeurons(), [-xavier, xavier]))
                #XAVIER INITIALISATION
                self.layers[-3].setBiases(mm.makematrix(layerObject.getNeurons(), 1, 0.01))

    def popLayer(self):
        self.layers.pop()
        

    def propagate_forwards(self, inp):
        for layer in self.layers:
            inp = layer.forward(inp)       
        return inp
    
    def propagate_backwards(self, dE_dO, rate):
        for layer in self.layers[::-1]:
            dE_dO = layer.backward(dE_dO, rate)
    
    def learn(self, inp, val_true, rate):
        inp = mm.copy(inp)
        output = self.propagate_forwards(inp)
        error = mm.msError(output, val_true)
        dE_dO = mm.dE_dO(output, val_true)
        self.propagate_backwards(dE_dO, rate)
       
    def training(self, data, results, rate, cycles):
        c = 0
        for cycle in range(cycles):
            nums = mm.testrand(len(data))
            c += 1
            if c%1000 == 0:
                print(c)
            for i in nums:  
                self.learn(mm.alter_dim(data[i], [0, 1]), mm.alter_dim(results[i], [0, 1]), rate)

