from matrices import mm
from layers import *

class NeuralNetwork:
    savedNetworks = []
    file = open("savedNetwork.txt", "r")
    for i in file:
        savedNetworks.append(i[:-1])
    file.close()
    
    @classmethod
    def view_saved(cls):
        for item in cls.savedNetworks[::2]:
            print(item, end  = ". ")
            
    @staticmethod
    def retrieve_saved(name, newname=None):
        if name not in NeuralNetwork.savedNetworks:
            return f"Error: '{name}' does not exist."
        else:
            index = NeuralNetwork.savedNetworks.index(name)
            cont = eval(NeuralNetwork.savedNetworks[index+1])
            if newname==None:
                uploadedNN = NeuralNetwork(name)
            else:
                uploadedNN = NeuralNetwork(newname)
            for layer in cont:
                uploadedNN.addLayer(layer)
            return uploadedNN
            
    def __init__(self, name):
        self.layers = []
        self.name = name
        #Index of latest hidden layer in nn, so as to be initialised with values if new hidden layer added
        self.lastHidden = None
             
    def addLayer(self, layer):
        
        #layer[0] contains the layer type
        if layer[0] == "Hidden":
            layerObject = Hidden(layer[1])
            #if the layer type is Hidden, will contain second item in list for number of neurons in this layer
            #if layer list length is greater than two, means there are values to assign parameters, so do not initialise.
            if len(layer) > 2:
                layerObject.setWeights(layer[2])
                layerObject.setNLbiases(layer[3])
            #otherwise, initialise params of previous Hidden layer
            elif self.lastHidden is not None:
                n = self.lastHidden
                xavier = 1/(self.layers[n].getNeurons())
                self.layers[n].setWeights(mm.makematrix(layer[1], self.layers[n].getNeurons(), [-xavier, xavier]))
                #XAVIER INITIALISATION
                self.layers[n].setNLbiases(mm.makematrix(layer[1], 1, 0.01))
                
            self.lastHidden = len(self.layers)
            
        elif layer[0] == "Convolutional":
            layerObject = Convolutional(layer[1], layer[2], layer[3], layer[4])
            if len(layer) > 5:
                layerObject.setKernels(layer[5])
                layerObject.setBiases(layer[6])
            else:
                kernels = []
                biases = []
                bias_size = ((layer[3][0]-layer[4][0]+1),(layer[3][1]-layer[4][1]+1))
                for i in range(layer[2]):
                    biases.append(mm.makematrix(bias_size[0], bias_size[1], 0.01))
                    temp = []
                    for j in range(layer[1]):
                        temp.append(mm.makematrix(layer[4][0], layer[4][1], [0, 0.01], True))
                    kernels.append(temp)
                layerObject.setKernels(kernels)
                layerObject.setBiases(biases)
                    
        elif layer[0] == "ReLU":
            layerObject = ReLU()
            
        elif layer[0] == "Softmax":
            layerObject = Softmax()
            
        elif layer[0] == "MaxPooling":
            layerObject = MaxPooling(layer[1], layer[2])
            
        else:
            return "Invalid layer type"
        
        layerObject.setIndex(len(self.layers))
        self.layers.append(layerObject)

    def propagate_forwards(self, inp):
        for layer in self.layers:
            inp = layer.forward(inp)       
        return inp
    
    def propagate_backwards(self, dE_dO, rate):
        for layer in self.layers[::-1]:
            dE_dO = layer.backward(dE_dO, rate)
        return dE_dO
    
                
    def train(self, data, results, rate, cycles, batch_size):
        rx, ry = mm.dim(results[0])  
        for cycle in range(cycles):
            error = mm.makematrix(rx, ry, 0)
            shuffled_nums = mm.testrand(len(data))
            c = 0
            temp = mm.makematrix(rx, ry, 0)
            for i in shuffled_nums:
                c+=1
                outp = self.propagate_forwards(data[i])
                error = mm.summatrix(error, mm.msError(outp, results[i]))
                dE_dO = mm.dE_dO(outp, results[i])
                temp = mm.summatrix(temp, dE_dO)
                if c%batch_size == 0:
                    self.propagate_backwards(mm.scalematrix(temp, (1/batch_size)), rate)
                    temp = mm.makematrix(rx, ry, 0)
            print(cycle+1, end=", ")
            print(sum([i[0] for i in error]))
            error = mm.makematrix(rx, ry, 0)
                
    def saveNN(self):
        if self.name in NeuralNetwork.savedNetworks:
            print("Network of this name already exists.")
        else:
            allLayers = []
            for layer in self.layers:
                layerInfo = []
                layerInfo.append(layer.getType())
                if layer.getType() == "Hidden":
                    layerInfo.append(layer.getNeurons())
                    layerInfo.append(layer.getWeights())
                    layerInfo.append(layer.getNLbiases())
                elif layer.getType() == "Convolutional":
                    layerInfo.append(layer.getInput_depth())
                    layerInfo.append(layer.getOutput_depth())
                    layerInfo.append(layer.getInput_size())
                    layerInfo.append(layer.getKernel_size())
                    layerInfo.append(layer.getKernels())
                    layerInfo.append(layer.getBiases())
                elif layer.getType() == "MaxPooling":
                    layerInfo.append(layer.getSize())
                    layerInfo.append(layer.getStride())
                allLayers.append(layerInfo)
            file = open("savedNetwork.txt", "a")
            file.write(f"{self.name}\n{allLayers}\n")
            file.close()
            NeuralNetwork.savedNetworks.append(self.name)
            NeuralNetwork.savedNetworks.append(str(allLayers))
            print(f"Neural network {self.name} saved")
            
    def displayLayers(self):
        for layer in self.layers:
            print(f"Layer: {layer.getType()}")

            if layer.getType() == "Hidden":
                print(f"Number of neurons: {layer.getNeurons()}")
                
                print(f'Weights matrix: {layer.getWeights()}')
                print(f"Next layer's biases matrix: {layer.getNLbiases()}")
                
            if layer.getType() == "Convolutional":
                print(f"Kernels: {layer.getKernels()}")
                print(f'Output depth: {len(layer.getKernels())}')
                print(f'Biases: {layer.getBiases()}')
                
            if layer.getType() == "MaxPooling":
                print(f"Size: {layer.getSize()}")
                print(f"Stride: {layer.getStride()}")

            print()
        
