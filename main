from NN2 import NeuralNetwork2
import time
import random
from matrices import mm
from layers import *
# This main is used mostly for testing or prototyping, which is why it is a mess currently

def timer():
    start_time = time.perf_counter()
    end_time = time.perf_counter()
    elapsed_time = end_time - start_time
    print("Elapsed time: ", elapsed_time)
#timer()

def main():
    
    data = [[0, 0], [0, 1], [1, 0], [1, 1]]
    results = [[0], [1], [1], [0]]
    obj0 = Hidden(2)
    obj1 = ReLU()    
    obj2 = Hidden(10)
    obj3 = ReLU()
    obj4 = Hidden(10)
    obj5 = ReLU()
    obj6 = Hidden(10)
    o7 = ReLU()
    o8 = Hidden(10)
    o9 = ReLU()
    o10 = Hidden(1)
    nt = NeuralNetwork2("MY_NN")
    nt.addLayer(obj0)
    nt.addLayer(obj1)
    nt.addLayer(obj2)
    nt.addLayer(obj3)
    nt.addLayer(obj4)
    nt.addLayer(obj5)
    '''
    nt.addLayer(obj6)
    nt.addLayer(o7)    
    nt.addLayer(o8)
    nt.addLayer(o9)
    '''
    nt.addLayer(o10)
    nt.training(data, results, 0.001 , 10000)
    
    print(nt.propagate_forwards([[0], [0]]))
    print(nt.propagate_forwards([[1], [0]]))
    print(nt.propagate_forwards([[0], [1]]))
    print(nt.propagate_forwards([[1], [1]]))
    


def m(a):
    for i in a:
        print(i)
    print("\n")


def main2():
    data = [[0, 0], [0, 1], [1, 0], [1, 1]]
    results = [[0], [1], [1], [0]]

    n = NeuralNetwork2("nut")
    layers = [["Hidden", 2], ["ReLU"], ["Hidden", 10], ["ReLU"], ["Hidden", 10], ["ReLU"], ["Hidden", 1]]
    for layer in layers:
        n.addLayer(layer)
    
    #n.displayLayers()

    n.training(data, results, 0.001, 10000)

    print(n.propagate_forwards([[0], [0]]))
    print(n.propagate_forwards([[1], [0]]))
    print(n.propagate_forwards([[0], [1]]))
    print(n.propagate_forwards([[1], [1]]))


def proc():
    file = open("mnist_train.csv", "r")
    file2 = open("processedData.txt", "w")
    for i in file:
        y = [0]*10
        y[int(i[0])] = 1
        x = list(map(lambda n: int(n)/255, i[:-1].split(",")[1:]))
        item = [x, y]
        file2.write(f"{str(item)}\n")
    file.close()
    file2.close()

    
def retProc(max=60000):
    file2 = open("processedData.txt", "r")
    c = 0
    data = []
    for i in file2:
        if c == max:
            file2.close()
            print("Data retrieval complete.")
            return data
        else:
            data.append(eval(i))
        c+=1

def getMax(lis):
    mx = 0
    c = 0
    tmp = 0
    for i in lis:
        if i > mx:
            mx = i
            tmp = c
        c+=1
    return tmp
    

def MNIST_TRAIN():
    train = retProc(1000)

    mNetwork = NeuralNetwork2("MNIST3")
    #layers = [["Hidden", 784], ["ReLU"], ["Hidden", 100], ["ReLU"], ["Hidden", 100], ["ReLU"], ["Hidden", 100], ["ReLU"], ["Softmax"], ["Hidden", 10]]
    layers = [["Hidden", 784], ["ReLU"], ["Hidden", 10], ["ReLU"], ["Softmax"], ["Hidden", 10]]

    for layer in layers:
        mNetwork.addLayer(layer)

    data = []
    results = []
    for i in train:  
        data.append(mm.alter_dim(i[0], [0,1]))
        results.append(mm.alter_dim(i[1], [0,1]))
    

    mNetwork.training(data, results, 0.01, 100)
    mNetwork.saveNN()
    return data, results


def MNIST_TEST(data, results, nn):

    n = NeuralNetwork2.upload_saved(nn)

    correct = 0
    total = 0
    for i in range(len(data)):    
        outp = n.propagate_forwards(data[i])
        res = [x[0] for x in results[i]]
        tmp = [x[0] for x in outp]
        pred = getMax(tmp)
        tru = getMax(res)
        total += 1
        if pred == tru:
            correct +=1
        if total%500==0:
            print(f"progress: {(total*100)/50000}% complete")    
    
    accuracy = (correct*100)/total
    print(f"\nAccuracy of the neural network: {accuracy}%\n")


def dispM(matrix):
    for i in matrix:
        print(i)

'''
Inp = [mm.makematrix(3, 3, 10),mm.makematrix(3, 3, 5)]
Ip = [mm.makematrix(3, 3, 4),mm.makematrix(3, 3, 4)]
n = NeuralNetwork2("nut")
n.addLayer(["Convolutional", 2, 3, (3,3), (2,2)])
outp= n.propagate_forwards(Inp)
outp = mm.scalematrix(outp, 0.01)
n.propagate_backwards(outp, 0.1)

'''
# --reshape--, activation functions, test

mnist = retProc(55000)
data = []
results = []
for i in mnist:

    tm = []
    trow = []
    for j in i[0]:
        trow.append(j)
        if len(trow) == 28:
            tm.append(trow)
            trow = []
        if len(tm) == 28:
            data.append([tm])
            tm = []
          
    results.append(mm.alter_dim(i[1], [0,1]))
   
'''
s1 = time.time()
n1 = NeuralNetwork2("test1")
layers1 = [["Convolutional", 1, 2, (28,28), (5, 5)], ["ReLU"], ["MaxPooling", (2,2), 2], ["Convolutional", 2, 4, (12,12), (3, 3)], ["ReLU"], ["MaxPooling", (2,2), 2], ["Hidden", 100], ["ReLU"], ["Softmax"], ["Hidden", 10]]
for layer in layers1:
    n1.addLayer(layer)

n1.training(data, results, 0.01, 15)
n1.saveNN()
e1 = time.time()

print(e1-s1)

'''
#n.saveNN()

#n = NeuralNetwork2.upload_saved("supremeNut")

'''
train = retProc(1024)
data = []
results = []
for i in train:  
    data.append(mm.alter_dim(i[0], [0,1]))
    results.append(mm.alter_dim(i[1], [0,1]))
'''
'''
name = "bestest"
n2 = NeuralNetwork2(name)
layers2 = [["Convolutional", 1, 3, (28,28), (5, 5)], ["ReLU"], ["MaxPooling", (2,2), 2], ["Hidden", 432], ["ReLU"], ["Softmax"], ["Hidden", 10]]
for layer in layers2:
    n2.addLayer(layer)

n2 = NeuralNetwork2.upload_saved("bestest", "b2")
n2.train2(data, results, 0.1, 10, 1)
n2.saveNN()
MNIST_TEST(data, results, "b2")'''

